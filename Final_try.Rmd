---
title: "Comparison of Different Y-transformations on House Price Data"
subtitle: "DS502 Final Project"
author: "Yufei Lin, Jingfeng Xia, Jinhong Yu, Shijing Yang, Yanze Wang"
date: "Nov 29 2020"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
references:
- id: Gareth01
  title: An Introduction to Statistical Learning with Applications in R
  author:
  - family: James
    given: Gareth

  URL: 'http://www.springer.com'
  DOI: 10.1007/978-1-4614-7138-7
  publisher: Springer
  page: 95-96
  type: book
  issued:
    year: 2013
    month: 9
- id: Kaggle
  title: Advanced Regression Techniques for House Prices

  URL: 'https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data?select=test.csv'
  
---

```{r setup, include=FALSE}
# check R version
R.Version()$major

# set up document
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")
knitr::opts_chunk$set(fig.width=5,fig.height=3)
knitr::opts_chunk$set(fig.align='center')
library(pander)
library(knitr)
library(skimr)
library(kableExtra)
library(tinytex)
library(dplyr)
library(purrr)
local({
  hook_inline = knitr::knit_hooks$get('inline')
  knitr::knit_hooks$set(inline = function(x) {
    res = hook_inline(x)
    if (is.numeric(x)) sprintf('$%s$', res) else res
  })
})

# define printf function
printf <- function(...)print(sprintf(...))
```

```{r libraries, include=FALSE}
# Import model libraries
library(pls)
library(randomForest)
library(gam)
library(glmnet)
library(ggplot2)
library(corrplot)
library(tidyverse)
library(caret)
library(mgcv)
library(Metrics)
library(visreg)
library(boot)
library('ggthemes') 
library('scales')
library('mice')
library('data.table')
library('gridExtra') 
library('GGally')
library('e1071')
library(Rmisc)
library(ggrepel)
library(psych)
library(xgboost)

```

# Introduction

Traditional house pricing prediction is by comparing the cost and sale price of that specific house. By doing this, it lacks a proper process and an accepted standard. Therefore,  being able to predict the price of a house by applying a machine learning model will help improve the efficiency of the real estate market and tends to be an important skill for both sellers and consumers. For the seller, they could make better sales and consumers could have better understanding when they try to make a purchase. Therefore, in this project, we are planning to make predictions of house price based on the 79 different predictors provided by Kaggle dataset [@Kaggle] to determine values of residential homes in Ames, Iowa. We are going to build several models based on this data set entirely in R and compare the results to find the model that performs the best in predicting sale price of houses.

 
    
# Approaches

## Model Selection

For our project, we are going to use regression analysis as our major method. Our goal is to predict the price of a certain house based on the location, type, space and other variables that can be considered in the real estate market that might affect the price of the house. There are multiple different methods to solve prediction problems. However, the reason why we chose regression as our method is because it is widely used in prediction and forecasting topics and it performs well with numeric data. Therefore, price prediction, as a numeric variable, would perform as a good fit with regression analysis.  

In terms of models, we are building 5 linear regression models.(Linear Regression Model, PCR, Ridge Regression, Lasso Regression and Random Forest). We are going to compare each of these models' performance and select the one that performs the best to be our best-performance model. After doing that, we will apply the model on our test data set to see its final performance.


## Y-value Transformation

We have noticed our target label SalePrice has a typical right-skewed distribution, which is against an assumption of linear regression -- residuals should follow normal distribution with zero mean and equal variance (homoscedasticity) [@Gareth01]. Since skewness is a serious issue and may be the reason for bad performance of a model, sometimes we can apply some transformations to reduce or remove Skewness. In general, square root transformation and log transformation. Log transformation is one of the most popular one and it does transform our data back to normal distribution. However, square root transformation did not do a good at transforming our data. Therefore we decided to use a new approach, which is using fourth root transformation in order to reduce the skewness. After applying log transformation and fourth-root transformation, the skewness of our data has become 0.07 and 0.49 repectively, which both fall into the category of being symmetric.


## Hierachical Cross Validation

We performed hierarchical cross validation on every model we build. Due to lacking data, we split 15% of our data as our testing data and this data is put in a vault. Then we took out 30% of the rest of the data as our testing data to test the performance of each model. Each model is built on a bootstrap sample of the remaining 70% of data with cross validation. After getting the result from the 30%-percent testing data set, we will choose the one that performs the best and apply that method on 15%-percent data set to see its actual performance.


## Error Metrics

We chose R square and RMSE as our error metrics to evaluate the performance of each model. Also, we created our own accuracy metric. In real world, customers tend to be satisfied when the house price is greater than its actual value since they can still bargain with the sellers; however they will be less satisfied when the predicted price is lower than the actual price. Therefore, we set our threshold to be between lower than -0.05% and greater than 20%, which means if the predicted price is within this range, we consider the predicted value as accurate.

## Additonal Data

In general, all columns provided are about the information and the facts of the house itself. However, considering other factors that might affect house prices (e.g. crime rate, neighborhood information), we added new columns from other data sets to add into this data set. We ended up adding the crime index, medium income, percentage of white collar and percentage of residents with college or higher degrees for each neighborhood.


# Data Processing

## Description of the Dataset

Our original training data set has 1460 rows and 84 columns without any duplicated rows. There are 43 categorical predictors and 40 numeric predictors. The target label of our data set is column "SalePrice", which makes our dataset only have one column for target labels. There are some noteworthy predictors include the location classification, utilities, environment of neighborhood, house style and condition, area, year of built, and number of functioning rooms.  

```{r readData}
setwd("~/Documents/DS502/DS502FinalProject")
HousePricing = read.csv("./SourceData/train_new.csv")
HousePricing = subset(HousePricing,select=-Id)
```

## Data Exploration

We first explored the distribution of our target label. As we mentioned before, our target values are right skewed, and we can also prove that by looking at Figure 1. 
```{r dimensionOfData, include=FALSE}
# The number of columns and rows
paste("Original training data set has",dim(HousePricing)[1], "rows and", dim(HousePricing)[2], "columns")

# # The percentage of data missing in train
# paste("The percentage of data missing in the original training data set is ", round(sum(is.na(HousePricing)) / (nrow(HousePricing) *ncol(HousePricing)),4)*100,"%",sep = "")

# The number of duplicated rows
paste("The number of duplicated rows are", nrow(HousePricing) - nrow(unique(HousePricing)))
```

```{r numOfNumericAndFactors,include=FALSE}
paste("Number of Categorical Predictors:",sum(sapply(HousePricing[,1:84],typeof) == "character"))

paste("Number of Numeric Predictors:",dim(HousePricing)[2]-sum(sapply(HousePricing[,1:84],typeof) == "character")-1)

paste("Number of target label:", 1)

```


### Target Varaible vs. Predictors

```{r saleprice, fig.width=5,fig.height=3,fig.cap="Distribution of Sale Price", fig.align='center'}
hist(HousePricing$SalePrice,col="blue",breaks = 25,main = "Distribution of Sale Price", xlab = "Sale Price")
```


```{r correlation, fig.width=8, fig.height=4, fig.cap="Numerical Data Correlation"}

numericVars <- which(sapply(HousePricing, is.numeric)) #index vector numeric variables
numericVarNames <- names(numericVars) #saving names vector for use later on
# cat('There are', length(numericVars), 'numeric variables')

all_numVar <- HousePricing[, numericVars]
cor_numVar <- cor(all_numVar, use="pairwise.complete.obs") #correlations of all numeric variables

#sort on decreasing correlations with SalePrice
cor_sorted <- as.matrix(sort(cor_numVar[,'SalePrice'], decreasing = TRUE))
 #select only high corelations
CorHigh <- names(which(apply(cor_sorted, 1, function(x) abs(x)>0.5)))
cor_numVar <- cor_numVar[CorHigh, CorHigh]

corrplot.mixed(cor_numVar, tl.col="black", tl.pos = "lt")
```

The correlation graph above shows that the predictors that have 0.5 or greater correlation with our target variable SalePrice. By looking at the plot above, we can see that 2 out of 4 columns that are newly added seem to have descent correlation with our target variable. According to the plot, neighborhoods with higher median income residents tend to have higher price houses. This scenario totally makes sense since people with higher income tend to be able to afford a more expensive house in general. Also, crime index of a neighborhood seems to play an important role in deciding the house price of that area on average. The higher crime index an area has, the lower of the house price it tends to have. However, it also becomes clear that there are multicollinearity issues in our data set. For example, predictor GarageCars and GarageArea are strongly correlated (0.89) as well as predictor CrimeIndex and MedianIncome (-0.8), and they are all relatively strongly correlated to the SalePrice predictor.

### Overall Quality

```{r overallquality, fig.height=3, fig.width=5, fig.cap="Overall Quality Box Plot"}
ggplot(data=HousePricing[!is.na(HousePricing$SalePrice),], aes(x=factor(OverallQual), y=SalePrice))+
        geom_boxplot(col='blue') + labs(x='Overall Quality') +
        scale_y_continuous(breaks= seq(0, 800000, by=100000), labels = comma)+theme_minimal()
```

Overall Quality is the predictor that is the most strongly correlated with target SalesPrice. As we can see the graph above, it is clear a upward curve and proves its positive correlation with SalePrice.

```{r LivingAreaoutliers, fig.width=5,fig.height=2, fig.cap="Living Area Scatter Plot"}
qplot(HousePricing$GrLivArea, HousePricing$SalePrice,col=HousePricing$GrLivArea>4500,xlab = "Ground Living Area (sqft)",ylab = "SalePrice")
```
```{r LivingAreaTable}
pander(HousePricing[HousePricing$GrLivArea > 4500,][c("GrLivArea", "OverallQual","SalePrice")], caption="Summary of Living Area")

```

Predictor "Ground Living Area" is the second most important numeric feature for SalePrice. We plotted a scatter plot for this predictor versus sale price. As we can see from the plot, there are two points that appear to be outliers since the living area of both houses are big but having relatively low prices. However, sometimes houses with poor quality can also lead to low prices. In order to further explore these two houses, we also plotted the overall quality of these two houses. According to the table, they are both listed as 10 in terms of quality. So we can basically make an assumption that these two points are outliers and it is relatively safe to remove these points from the data set.


# Feature Engineering
## Missing values 
The very first thing to handle is the missing values of this data set. Overall, there are 35 columns with missing values. Usually, the rule of thumb to delete a column where there are more than 30% missing values. We have created a rule to handle numeric missing values and categorical missing values separately. For numeric missing values, we generally apply the median value of the corresponding column; for categorical missing values, we generally apply the most common category of that specific column. Also, for values that can be interpreted as none (e.g. no swimming pool), we replace those missing values to "None".


## Numeric Predictors
### Data normalization
After handling all missing values for numeric data, we simply apply a normalization function on our numeric columns to scale the numeric predictors, since it will help to generate a model that provides better accuracy on average.

### Factorization
Some columns with numeric values are actually categorical data. We apply the corresponding explanation to replace the actual number then change them to factors.

## Categorical Predictors
### Ordinal Data
For categorical predictors, we apply two different ways to handle different types of them. For columns that can be interpreted as ordinal data, we scale them from 0-5. 

### Factorization
For other categorical predictors, we simply apply a factor function to make them become a factor within the data frame.

## New Predictors
We also manually added some new predictors. For example, we combine the area of the basement and ground area of the house to become a new predictor called "TotalSqft".
Figure 6 shows the relationship between new added features with our target label "SalePrice". Moreover, we use the predictor “YearSold” minus “YearBuilt” to create a predictor "Age".According to figure 6, it is obvious that the sale price of a house decreases as the age of the house increases. Also, houses that have been remodeled tend to have a higher price than those that have not, and it is the same for houses that are newer than older houses. Based on Figure 7, the new added variables such as "Age" and "TotaSqft" which have higher than 0.5 correlation with target variable "SalePrice".

## Dropping columns
After doing all steps above, we then delete columns that fall into multicollinearity issue category, columns that contain over 95% same values as well as those outliers.

```{r featuerEngineering, include=FALSE}
# remove ID column
HousePricing$Id = NULL
HousePricing = HousePricing[HousePricing$GrLivArea<4500,]

# for using later
numericVars <- which(sapply(HousePricing, is.numeric))
numericVarNames <- names(numericVars) 

# LotFrontage
# compute the median of neighbor, na.rm means compute medians without NA
paste("There are",dim(HousePricing[is.na(HousePricing$LotFrontage),])[1],"rows with NAs in LotFrontage column")
neighbor_Median  = HousePricing %>%
  select(LotFrontage, Neighborhood) %>%
  group_by(Neighborhood) %>%
  summarise(LotFrontage = median(LotFrontage, na.rm = T))
print(neighbor_Median)

# replace the LotFrontage NA with its neighbor's Lotfrontage's median.
for (i in 1:nrow(HousePricing))
{
  if(is.na(HousePricing$LotFrontage[i])){
               HousePricing$LotFrontage[i] <- as.integer(median(HousePricing$LotFrontage[HousePricing$Neighborhood==HousePricing$Neighborhood[i]], na.rm=TRUE)) 
        }
}

# Alley, NA means no alley.
HousePricing$Alley[is.na(HousePricing$Alley)] = 'None'
HousePricing$Alley = as.factor(HousePricing$Alley)

# For utilites, there are two NAs, one row in one category, and the rest all share the same category
# Therefore we remove the entire column
# table(HousePricing$Utilities)
HousePricing$Utilities = NULL

# Pool variables are the ones with most NAs
# 1. Assign NAs to None (suppose those houses do not have a pool)
table(HousePricing$PoolQC)
HousePricing$PoolQC[is.na(HousePricing$PoolQC)] = "None"

# 2. Change it to Ordinal (scale them into numbers)
HousePricing$PoolQC=recode(HousePricing$PoolQC,'None' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)


# Fence
HousePricing$Fence[is.na(HousePricing$Fence)] = "None"
HousePricing$Fence = as.factor(HousePricing$Fence)

# Miscellaneous features
HousePricing$MiscFeature[is.na(HousePricing$MiscFeature)] = "None"
HousePricing$MiscFeature = as.factor(HousePricing$MiscFeature)



# garage
# replace NAs with the year that the house was built
HousePricing$GarageYrBlt[is.na(HousePricing$GarageYrBlt)] <- HousePricing$YearBuilt[is.na(HousePricing$GarageYrBlt)]
# garage type dost not seem to be ordinal, then convert to factors
HousePricing$GarageType[is.na(HousePricing$GarageType)] = "None"
HousePricing$GarageType = as.factor(HousePricing$GarageType)

# convert to ordinals
HousePricing$GarageFinish[is.na(HousePricing$GarageFinish)] = "None"
HousePricing$GarageFinish=recode(HousePricing$GarageFinish,'None' = 0,'Unf' = 1,'RFn' = 2,'Fin' = 3)
HousePricing$GarageQual[is.na(HousePricing$GarageQual)] = "None"
HousePricing$GarageQual=recode(HousePricing$GarageQual,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)
HousePricing$GarageCond[is.na(HousePricing$GarageCond)] = "None"
HousePricing$GarageCond=recode(HousePricing$GarageCond,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)
HousePricing$FireplaceQu[is.na(HousePricing$FireplaceQu)] = "None"
HousePricing$FireplaceQu=recode(HousePricing$FireplaceQu,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)

#electric
# only one missing value, convert it to most common type
HousePricing$Electrical[is.na(HousePricing$Electrical)] = "SBrkr"
HousePricing$Electrical = as.factor(HousePricing$Electrical)

# basement
length(which(is.na(HousePricing$BsmtQual) & is.na(HousePricing$BsmtCond) & is.na(HousePricing$BsmtExposure) & is.na(HousePricing$BsmtFinType1) & is.na(HousePricing$BsmtFinType2)))
HousePricing[!is.na(HousePricing$BsmtCond) & (is.na(HousePricing$BsmtFinType1)|is.na(HousePricing$BsmtQual)|is.na(HousePricing$BsmtExposure)|is.na(HousePricing$BsmtFinType2)), c('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2')]
HousePricing$BsmtFinType2[333] = names(sort(table(HousePricing$BsmtFinType2),decreasing = TRUE))[1]
HousePricing$BsmtExposure[949] = names(sort(table(HousePricing$BsmtExposure),decreasing = TRUE))[1]

# convert to ordinal 
HousePricing$BsmtExposure[is.na(HousePricing$BsmtExposure)] = 'None'
HousePricing$BsmtExposure=recode(HousePricing$BsmtExposure,'None' = 0,'No' = 1,'Mn' = 2,'Av' = 3,'Gd' = 4)
HousePricing$BsmtQual[is.na(HousePricing$BsmtQual)] = 'None'
HousePricing$BsmtQual=recode(HousePricing$BsmtQual,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)
HousePricing$BsmtCond[is.na(HousePricing$BsmtCond)] = 'None'
HousePricing$BsmtCond=recode(HousePricing$BsmtCond,'None' = 0,'Po' = 1,'Fa' = 2,'TA' = 3,'Gd' = 4,'Ex' = 5)
HousePricing$BsmtFinType1[is.na(HousePricing$BsmtFinType1)] = 'None'
HousePricing$BsmtFinType1=recode(HousePricing$BsmtFinType1,'None' = 0,'Unf' = 1,'LwQ' = 2,'Rec' = 3,'BLQ' = 4,'ALQ' = 5, 'GLQ' = 6)
HousePricing$BsmtFinType2[is.na(HousePricing$BsmtFinType2)] = 'None'
HousePricing$BsmtFinType2=recode(HousePricing$BsmtFinType2,'None' = 0,'Unf' = 1,'LwQ' = 2,'Rec' = 3,'BLQ' = 4,'ALQ' = 5, 'GLQ' = 6)

# Mas
# missing value set to none
HousePricing$MasVnrType[is.na(HousePricing$MasVnrType)] = 'None'
HousePricing$MasVnrType = as.factor(HousePricing$MasVnrType)
HousePricing$MasVnrArea[(is.na(HousePricing$MasVnrArea))] = 0


# MS Zoning
# categorical --> factor
HousePricing$MSZoning = as.factor(HousePricing$MSZoning)

# street

# categorical --> factor
HousePricing$Street = as.factor(HousePricing$Street)
HousePricing$LotShape=recode(HousePricing$LotShape,'IR3' = 0,'IR2' = 1,'IR1' = 2,'Reg' =2)
HousePricing$LotConfig = as.factor(HousePricing$LotConfig)


# House condition
HousePricing$Condition1 = as.factor(HousePricing$Condition1)
HousePricing$Condition2 = as.factor(HousePricing$Condition2)

# categorical
HousePricing$LandContour = as.factor(HousePricing$LandContour)


# categorical
HousePricing$RoofStyle = as.factor(HousePricing$RoofStyle)

# ordinal
HousePricing$LandSlope=recode(HousePricing$LandSlope,'Sev' = 0,'Mod' = 1,'Gtl' = 2)


# categorical
HousePricing$BldgType = as.factor(HousePricing$BldgType)
HousePricing$HouseStyle=as.factor(HousePricing$HouseStyle)


HousePricing$RoofMatl=as.factor(HousePricing$RoofMatl)
HousePricing$Exterior1st=as.factor(HousePricing$Exterior1st)
HousePricing$Exterior2nd=as.factor(HousePricing$Exterior2nd)
HousePricing$ExterQual=recode(HousePricing$ExterQual,'Po' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)
HousePricing$ExterCond=recode(HousePricing$ExterCond,'Po' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)

HousePricing$Foundation = as.factor(HousePricing$Foundation)
HousePricing$PavedDrive=recode(HousePricing$PavedDrive,'N' = 0,'P' = 1,'Y' = 2)
HousePricing$Heating = as.factor(HousePricing$Heating)
HousePricing$HeatingQC=recode(HousePricing$HeatingQC,'Po' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)
HousePricing$CentralAir=recode(HousePricing$CentralAir,'N' = 0,'Y' = 1)

# Kitchen variables
HousePricing$KitchenQual=recode(HousePricing$KitchenQua,'Po' = 0,'Fa' = 1,'TA' = 2,'Gd' = 3,'Ex' = 4)


HousePricing$Functional=recode(HousePricing$Functional,'Sal' = 0,'Sev' = 1,'Maj2' = 2,'Maj1' = 3,'Mod' = 4,'Min2' = 5,'Min1' = 6,'Typ' = 7)
# Neighborhood 
HousePricing$Neighborhood = as.factor(HousePricing$Neighborhood)
# Sale type
HousePricing$SaleType = as.factor(HousePricing$SaleType)
# Sale condition
HousePricing$SaleCondition = as.factor(HousePricing$SaleCondition)

# drop month sold
HousePricing$MoSold = NULL
HousePricing$MSSubClass = as.factor(HousePricing$MSSubClass)
# switch to factor 
HousePricing$MSSubClass=recode(HousePricing$MSSubClass,'20' = '1-STORY 1946+',
                               '30' = '1-STORY 1945-','40' = '1-STORY Unf Attic',
                               '45' = "1/2 STORY Unf Attic",'50' = '1/2 STORY Fin',
                               '60' = '2-STORY+','70' = '2-STORY 1945-','80' = 'SPLIT OR MULTI-LEVEL',
                               '85' = 'SPLIT FOYER','90' = 'DUPLEX', '120' = '1-STORY PUD 1946+',
                               '150' = '1/2 STORY PUD','160' = '2-STORY PUD 1946+',
                               '180' = 'PUD - MULTILEVEL',' 190' = '2 FAMILY CONVERSION')




```




```{r corNum, include=FALSE}
# draw a plot of correlation between numerical variables in original data
#which(sapply(HousePricing, is.numeric))
numericVars = which(sapply(HousePricing, is.numeric))#numericVars
factorVars = which(sapply(HousePricing, is.factor))
cat('There are', length(numericVars), 'numeric variables, and', length(factorVars), 'categoric variables')
numVar = HousePricing[,numericVars]
cor_numVar =(cor(numVar))
cor_sorted = as.matrix(sort(cor_numVar[,"SalePrice"],decreasing = TRUE))
#cor_sorted
# CorHigh <- names(which(apply(cor_sorted, 1, function(x) abs(x)>0.5)))
# cor_numVar <- cor_numVar[CorHigh, CorHigh]
# corrplot.mixed(cor_numVar, tl.col="black", tl.pos = "lt", tl.cex = 0.7,cl.cex = .7, number.cex=.7)

# draw a importance plot of all predictors in the original data
# set.seed(2018)
# quick_RF <- randomForest(x=HousePricing[,-78], y=HousePricing$SalePrice, ntree=100,importance=TRUE)
# imp_RF <- importance(quick_RF)
# imp_DF <- data.frame(Variables = row.names(imp_RF), MSE = imp_RF[,1])
# imp_DF <- imp_DF[order(imp_DF$MSE, decreasing = TRUE),]
# ggplot(imp_DF[1:15,], aes(x=reorder(Variables, MSE), y=MSE, fill=MSE)) + geom_bar(stat = 'identity') + labs(x = 'Variables', y= '% increase MSE if variable is randomly permuted') + coord_flip() + theme(legend.position="none")

```

```{r categorical predictors, warning=FALSE, message=FALSE, fig.height=5, fig.width=8, fig.cap="Neighborhood Analysis"}
n1 <- ggplot(HousePricing[!is.na(HousePricing$SalePrice),], aes(x=Neighborhood, y=SalePrice)) +
        geom_bar(stat='summary', fun.y = "median", fill='blue') +
        scale_y_continuous(breaks= seq(0, 800000, by=50000), labels = comma) +
        geom_label(stat = "count", aes(label = ..count.., y = ..count..), size=3) +
        geom_hline(yintercept=163000, linetype="dashed", color = "red")+
        theme(axis.text.x = element_text(angle = 45, hjust = 1),panel.background =        element_rect(fill = "white",colour = "white",
                                size = 0.5, linetype = "solid"),
  panel.grid.major = element_line(size = 0.1, linetype = 'solid',
                                colour = "black"), 
  panel.grid.minor = element_line(size = 0.1, linetype = 'solid',
                                colour = "black"))
#dashed line is median SalePrice
n2 <- ggplot(data=HousePricing, aes(x=Neighborhood)) +
        geom_histogram(stat='count')+
        geom_label(stat = "count", aes(label = ..count.., y = ..count..), size=3)+
        theme(axis.text.x = element_text(angle = 45, hjust = 1),panel.background =        element_rect(fill = "white",colour = "white",
                                size = 0.5, linetype = "solid"),
  panel.grid.major = element_line(size = 0.1, linetype = 'solid',
                                colour = "black"), 
  panel.grid.minor = element_line(size = 0.1, linetype = 'solid',
                                colour = "black"))

grid.arrange(n1, n2)

```

```{r ffe, include=FALSE}
########################### further feature engineer ###################
# whether remod 
HousePricing$Remod = ifelse(HousePricing$YearBuilt == HousePricing$YearRemodAdd,0,1)
# the age of house 
HousePricing$Age = as.numeric(HousePricing$YrSold) - HousePricing$YearRemodAdd 
# whether is new
HousePricing$isnew = ifelse(HousePricing$YrSold == HousePricing$YearBuilt,1,0)
# total area.
HousePricing$TotalSqFeet = HousePricing$GrLivArea+HousePricing$TotalBsmtSF
# count the totol number of bathroom in the hourse
HousePricing$TotBathrooms <- HousePricing$FullBath + (HousePricing$HalfBath*0.5) + HousePricing$BsmtFullBath + (HousePricing$BsmtHalfBath*0.5)

HousePricing$TotalPorchSF <- HousePricing$OpenPorchSF + HousePricing$EnclosedPorch + HousePricing$X3SsnPorch + HousePricing$ScreenPorch

# draw a correlation plot after combine some variable
numericVars = which(sapply(HousePricing, is.numeric))#numericVars
factorVars = which(sapply(HousePricing, is.factor))
numVar = HousePricing[,numericVars]
cor_numVar =(cor(numVar))
cor_sorted = as.matrix(sort(cor_numVar[,"SalePrice"],decreasing = TRUE))
#cor_sorted
CorHigh <- names(which(apply(cor_sorted, 1, function(x) abs(x)>0.5)))
cor_numVar <- cor_numVar[CorHigh, CorHigh]
corrplot.mixed(cor_numVar, tl.col="black", tl.pos = "lt", tl.cex = 0.7,cl.cex = .7, number.cex=.7)

# choose some true numerical variable to normalize(not include the encoded part)
numericVarNames <- numericVarNames[!(numericVarNames %in% c('MSSubClass', 'MoSold', 'YrSold', 'SalePrice', 'OverallQual', 'OverallCond'))]
numericVarNames <- append(numericVarNames, c('Age', 'TotalPorchSF', 'TotBathrooms', 'TotalSqFeet'))

# delete some highly correlated variables
HousePricing = subset(HousePricing, select = -c(GrLivArea,ExterQual,GarageArea,X1stFlrSF,
                                           TotRmsAbvGrd,TotalBsmtSF,GarageYrBlt,FullBath,
                                           HalfBath,YearRemodAdd,BsmtHalfBath,BsmtFullBath))
DFnumeric <- HousePricing[, names(HousePricing) %in% numericVarNames]
DFfactors <- HousePricing[, !(names(HousePricing) %in% numericVarNames)]
DFfactors <- DFfactors[, names(DFfactors) != 'SalePrice']

########################## Normalizing the numerical data #########################
predf = scale(DFnumeric,center = T,scale = T)

```

```{r newPredictors , fig.cap="new predictors",echo=FALSE}


p1 = ggplot(data=HousePricing[!is.na(HousePricing$SalePrice),], aes(x=Age, y=SalePrice))+
        geom_point(col='light blue') + geom_smooth(method = "lm", se=FALSE, color="black", aes(group=1)) +
        scale_y_continuous(breaks= seq(0, 800000, by=100000), labels = comma)
p2 = ggplot(HousePricing[!is.na(HousePricing$SalePrice),], aes(x=as.factor(Remod), y=SalePrice)) +
        geom_bar(stat='summary', fun.y = "median", fill='dark green') +
        geom_label(stat = "count", aes(label = ..count.., y = ..count..), size=3) +
        scale_y_continuous(breaks= seq(0, 800000, by=50000), labels = comma) +
        theme_grey(base_size = 10) +
        geom_hline(yintercept=163000, linetype="dashed") #dashed line is median SalePrice

p3 = ggplot(HousePricing[!is.na(HousePricing$SalePrice),], aes(x=as.factor(isnew), y=SalePrice)) +
        geom_bar(stat='summary', fun.y = "median", fill='dark green') +
        geom_label(stat = "count", aes(label = ..count.., y = ..count..), size=3) +
        scale_y_continuous(breaks= seq(0, 800000, by=50000), labels = comma) +
        theme_grey(base_size = 10) +
        geom_hline(yintercept=163000, linetype="dashed") #dashed line is median SalePrice

p4 = ggplot(data=HousePricing[!is.na(HousePricing$SalePrice),], aes(x=TotalSqFeet, y=SalePrice))+
        geom_point(col='dark red') + geom_smooth(method = "lm", se=FALSE, color="black", aes(group=1)) +
        scale_y_continuous(breaks= seq(0, 800000, by=100000), labels = comma)

# grid.arrange(p2,p3)
grid.arrange(p1,                                    # bar plot spaning two columns
             p2, p3,                               # box plot and scatter plot
             ncol = 2, nrow = 4, 
             layout_matrix = rbind(c(1,1), c(2,3)))
```

``` {r correlation2, message=FALSE, fig.cap="Correlation of numeric predictors"}
# draw a correlation plot after combine some variable
numericVars = which(sapply(HousePricing, is.numeric))#numericVars
factorVars = which(sapply(HousePricing, is.factor))
numVar = HousePricing[,numericVars]
cor_numVar =(cor(numVar))
cor_sorted = as.matrix(sort(cor_numVar[,"SalePrice"],decreasing = TRUE))
#cor_sorted
CorHigh <- names(which(apply(cor_sorted, 1, function(x) abs(x)>0.5)))
cor_numVar <- cor_numVar[CorHigh, CorHigh]
corrplot.mixed(cor_numVar, tl.col="black", tl.pos = "lt", tl.cex = 0.7,cl.cex = .7, number.cex=.7)
```


```{r getFinalData, fig.width=7, fig.height=4, fig.cap="Histogram Comparison"}
############ one-hot encoding and combine with scaled numerical data ###########
dfdummies = model.matrix(~.-1,DFfactors) %>% as.data.frame()
newdata = cbind(predf,dfdummies)
newdata$SalePrice = HousePricing$SalePrice

set.seed(1)
vault = sample(1:nrow(newdata), nrow(newdata)*0.15)
dVault = newdata[vault,]
newdata = newdata[-vault,]
oriHouseP = newdata
oriHouseP$SalePrice = newdata$SalePrice
sumOri = summary(oriHouseP$SalePrice)
par(mfrow=c(1,2))
#pander(sumOri, caption="Summary of Original Y-Value")
logHouseP = newdata
logHouseP$SalePrice = log(newdata$SalePrice)
sumLog = summary(logHouseP$SalePrice)
hist(logHouseP$SalePrice, col="blue", main="Histogram of Logged Sale Price",cex.main=1)
#pander(sumLog, caption="Summary of Log Transformed Y-Value")
sqrtHouseP = newdata
sqrtHouseP$SalePrice = '^'(newdata$SalePrice,1/4)
sumSqrt = summary(sqrtHouseP$SalePrice)
hist(sqrtHouseP$SalePrice, col="blue", main="Histogram of Forth Rooted Sale Price",cex.main=1)
#pander(sumSqrt, caption="Summary of Fourth Root Transformed Y-Value")
```

```{r bootstrapingFunc, include=FALSE}
bsF<- function(datadf, randomizer){
  set.seed(randomizer)
  sample = sample(dim(datadf)[1],dim(datadf)[1],replace = T)
  btnewdata = datadf[sample,]
  return(btnewdata)
}
newOriHouseP = bsF(oriHouseP, 1234)
newLogHouseP = bsF(logHouseP, 1111)
newSqrtHouseP = bsF(sqrtHouseP, 1332)
```

```{r saveToCSV, include=FALSE}
toCsv <- function(df, fileName){
  set.seed(10)
  randS = sample(1:nrow(df), nrow(df)*0.7)
  train = df[randS,]
  test = df[-randS,]
  write.csv(train,paste("./SourceData/train_",fileName, ".csv",sep=""), row.names = FALSE)
  write.csv(test,paste("./SourceData/test_",fileName, ".csv",sep=""), row.names = FALSE)
}
setwd("~/Documents/DS502/DS502FinalProject")
toCsv(oriHouseP, "original")
toCsv(logHouseP, "log")
toCsv(sqrtHouseP, "sqrt")
```

```{r oriTestTrainReg, include=FALSE}
setwd("~/Documents/DS502/DS502FinalProject")
test_ori = read.csv("./SourceData/test_original.csv")
y_test_ori = test_ori$SalePrice
x_test_ori = subset (test_ori, select = -SalePrice)
train_ori = read.csv("./SourceData/train_original.csv")
y_train_ori = train_ori$SalePrice
x_train_ori = subset (train_ori, select = -SalePrice)
y_train_ori = as.numeric(y_train_ori)
y_test_ori = as.numeric(y_test_ori)
summary(y_train_ori)
```

```{r logTestTrainReg, include=FALSE}
setwd("~/Documents/DS502/DS502FinalProject")
test_log = read.csv("./SourceData/test_log.csv")
y_test_log = test_log$SalePrice
x_test_log = subset (test_log, select = -SalePrice)
train_log = read.csv("./SourceData/train_log.csv")
y_train_log = train_log$SalePrice
x_train_log = subset (train_log, select = -SalePrice)
y_train_log = as.numeric(y_train_log)
y_test_log = as.numeric(y_test_log)
summary(y_train_log)
```

```{r sqrtTestTrainReg, include=FALSE}
setwd("~/Documents/DS502/DS502FinalProject")

test_sqrt = read.csv("./SourceData/test_sqrt.csv")
y_test_sqrt = test_sqrt$SalePrice
x_test_sqrt = subset (test_sqrt, select = -SalePrice)
train_sqrt = read.csv("./SourceData/train_sqrt.csv")
y_train_sqrt = train_sqrt$SalePrice
x_train_sqrt = subset (train_sqrt, select = -SalePrice)
y_train_sqrt = as.numeric(y_train_sqrt)
y_test_sqrt = as.numeric(y_test_sqrt)
summary(y_train_sqrt)
```


# Regression Methods

We choose to use linear regression, random forest, Principle Components Regression (PCR), Lasso and Ridge regression to look at how each model would be suitable for our regression analysis. 

## 1. Linear Regression 

A simple linear regression model is the first model we build. The reason why we chose this model is because we want to understand how each numeric variable is linear related to our House Price prediction. We applied linear regression model on original y value, log's transformation y as well as fourth-root y transformation to test its performance one by one. Then we tested the model on our test data set and got the result. 

```{r lr ori}
# ori
k = 5
lm_ori_accuracy = rep(0,k)
lm_ori_train = rep(0,k)
lm_ori_R2 = rep(0,k)
lm_ori_RMSE = rep(0,k)
for (i in 1:k){
  set.seed(5+i)
  sample = sample(nrow(train_ori),nrow(train_ori),replace = T)
  ori_train = train_ori[sample,]
  train = sample(nrow(ori_train),0.7*nrow(ori_train))
  training_dataset = ori_train[train,]
  validation_dataset = ori_train[-train,]
  lm_ori_model = lm(formula = SalePrice ~.,data = training_dataset)
  lm_ori_pred1 = predict(lm_ori_model,newdata = training_dataset)
  lm_ori_pred = predict(lm_ori_model,newdata = validation_dataset)
  lm_ori_accuracy[i] = mean(-0.05<=(((lm_ori_pred)-(validation_dataset$SalePrice))/(validation_dataset$SalePrice))&(((lm_ori_pred)-(validation_dataset$SalePrice))/(validation_dataset$SalePrice)) <=0.2)
  lm_ori_train[i] = mean(-0.05<=(((lm_ori_pred1)-(training_dataset$SalePrice))/(training_dataset$SalePrice))&(((lm_ori_pred1)-(training_dataset$SalePrice))/(training_dataset$SalePrice)) <=0.2)
  lm_ori_R2[i] = R2(lm_ori_pred, (validation_dataset$SalePrice))
  lm_ori_RMSE[i] = RMSE(lm_ori_pred, (validation_dataset$SalePrice))
  }
lm_ori_aver_accuracy = mean(lm_ori_accuracy)
lm_ori_aver_train = mean(lm_ori_train)
lm_ori_aver_R2 = mean(lm_ori_R2)
lm_ori_aver_RMSE = mean(lm_ori_RMSE)
```

```{r lr log}
k = 5
lm_log_accuracy = rep(0,k)
lm_log_train = rep(0,k)
lm_log_R2 = rep(0,k)
lm_log_RMSE = rep(0,k)
for (i in 1:k){
  set.seed(100+i)
  sample = sample(nrow(train_log),nrow(train_log),replace = T)
  log_train = train_log[sample,]
  train = sample(nrow(log_train),0.7*nrow(log_train))
  training_dataset = log_train[train,]
  validation_dataset = log_train[-train,]
  lm_log_model = lm(formula = SalePrice ~.,data = training_dataset)
  lm_log_pred1 = predict(lm_log_model,newdata = training_dataset)
  lm_log_pred1 = exp(lm_log_pred1)
  lm_log_pred = predict(lm_log_model,newdata = validation_dataset)
  lm_log_pred = exp(lm_log_pred)
  lm_log_accuracy[i] = mean(-0.05<=(((lm_log_pred)-exp(validation_dataset$SalePrice))/exp(validation_dataset$SalePrice))&(((lm_log_pred)-exp(validation_dataset$SalePrice))/exp(validation_dataset$SalePrice)) <=0.2)
  lm_log_train[i] = mean(-0.05<=(((lm_log_pred1)-exp(training_dataset$SalePrice))/exp(training_dataset$SalePrice))&(((lm_log_pred1)-exp(training_dataset$SalePrice))/exp(training_dataset$SalePrice)) <=0.2)
  lm_log_R2[i] = R2(lm_log_pred, exp(validation_dataset$SalePrice))
  lm_log_RMSE[i] = RMSE(lm_log_pred, exp(validation_dataset$SalePrice))
  }
lm_log_aver_accuracy = mean(lm_log_accuracy)
lm_log_aver_train = mean(lm_log_train)
lm_log_aver_R2 = mean(lm_log_R2)
lm_log_aver_RMSE = mean(lm_log_RMSE)
```

```{r lr sqrt}
# sqrt 
lm_sqrt_accuracy = rep(0,k)
lm_sqrt_train = rep(0,k)
lm_sqrt_R2 = rep(0,k)
lm_sqrt_RMSE = rep(0,k)
for (i in 1:k){
  set.seed(50+i)
  sample = sample(nrow(train_sqrt),nrow(train_sqrt),replace = T)
  sqrt_train = train_sqrt[sample,]
  train = sample(nrow(sqrt_train),0.7*nrow(sqrt_train))
  training_dataset = sqrt_train[train,]
  validation_dataset = sqrt_train[-train,]
  lm_sqrt_model = lm(formula = SalePrice ~.,data = training_dataset)
  lm_sqrt_pred1 = predict(lm_sqrt_model,newdata = training_dataset)
  lm_sqrt_pred1 = lm_sqrt_pred1^4
  lm_sqrt_pred = predict(lm_sqrt_model,newdata = validation_dataset)
  lm_sqrt_pred = lm_sqrt_pred^4
  lm_sqrt_train[i] = mean(-0.05<=(((lm_sqrt_pred1)-(training_dataset$SalePrice)^4)/(training_dataset$SalePrice)^4)&(((lm_sqrt_pred1)-(training_dataset$SalePrice)^4)/(training_dataset$SalePrice)^4) <=0.2)
  lm_sqrt_accuracy[i] = mean(-0.05<=(((lm_sqrt_pred)-(validation_dataset$SalePrice)^4)/(validation_dataset$SalePrice)^4)&(((lm_sqrt_pred)-(validation_dataset$SalePrice)^4)/(validation_dataset$SalePrice)^4) <=0.2)
  lm_sqrt_R2[i] = R2(lm_sqrt_pred, (validation_dataset$SalePrice)^4)
  lm_sqrt_RMSE[i] = RMSE(lm_sqrt_pred, (validation_dataset$SalePrice)^4)
  }
lm_sqrt_aver_accuracy = mean(lm_sqrt_accuracy)
lm_sqrt_aver_train = mean(lm_sqrt_train)
lm_sqrt_aver_R2 = mean(lm_sqrt_R2)
lm_sqrt_aver_RMSE = mean(lm_sqrt_RMSE)

```


```{r lr2, include=FALSE}
# Multiple R-squared: 0.9475, 
# Adjusted R-squared: 0.9345  
# F-statistic:  73.09  on 289 and 1170 DF, 
# p-value: < 2.2e-16

accLr = c(lm_ori_aver_accuracy, lm_log_aver_accuracy,lm_sqrt_aver_accuracy)
r2Lr = c(lm_ori_aver_R2,lm_log_aver_R2,lm_sqrt_aver_R2)
rmseLr = c(lm_ori_aver_RMSE,lm_log_aver_RMSE,lm_sqrt_aver_RMSE)

  
```

## 2. Random Forest

### Explanation

We have chosen this model because random forest is based on a collection of decision trees that could help us get better understanding of which tree and division contribute to which section such that we could have a better picture of the overall importance of each different factor in the prediction.

### Prepare Model

We have $199$ independent variables in the data set, therefore we have set mtry(Number of randomly selected variables for each split) to be the square root of that number for maximum performance of the model. 

The following is the result from Random Forest algorithm: 

1) Original Data Prediction Model

```{r rf-preparemodel_ori}
# Need to figure out how many independent variables then set mtry
# set mtry to be square root of total number of independent variables
totalIV = length(colnames(train_ori))
rfTrain_ori=randomForest(SalePrice~.,data=train_ori, mtry=sqrt(totalIV),importance =TRUE)
pander(rfTrain_ori)
```

2) Log Transformed Data Prediction Model

```{r rf-preparemodel_log}
# Need to figure out how many independent variables then set mtry
# set mtry to be square root of total number of independent variables
totalIV = length(colnames(train_log))
rfTrain_log=randomForest(SalePrice~.,data=train_log, mtry=sqrt(totalIV),importance =TRUE)
pander(rfTrain_log)
```

3) Forth Root Transformed Data Prediction Model

```{r rf-preparemodel_sqrt}
# Need to figure out how many independent variables then set mtry
# set mtry to be square root of total number of independent variables
totalIV = length(colnames(train_sqrt))
rfTrain_sqrt=randomForest(SalePrice~.,data=train_sqrt, mtry=sqrt(totalIV),importance =TRUE)
pander(rfTrain_sqrt)
```

```{r rfAccuracy_ori, include=FALSE}
rfYhat_ori = predict(rfTrain_ori, newdata=x_test_ori)
#table(y_test, rfYhat)
rf_accuracy_ori = mean(((y_test_ori - rfYhat_ori)/y_test_ori<=0.2) & ((y_test_ori - rfYhat_ori)/y_test_ori>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", rf_accuracy_ori*100)
```

```{r rfAccuracy_log, include=FALSE}
rfYhat_log = predict(rfTrain_log, newdata=x_test_log)
#table(y_test, rfYhat)
rf_accuracy_log = mean(((exp(y_test_log) - exp(rfYhat_log))/exp(y_test_log)<=0.2) & ((exp(y_test_log) - exp(rfYhat_log))/exp(y_test_log)>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", rf_accuracy_log*100)
```

```{r rfAccuracy_sqrt, include=FALSE}
rfYhat_sqrt = predict(rfTrain_sqrt, newdata=x_test_sqrt)
#table(y_test, rfYhat)
rf_accuracy_sqrt = mean(((y_test_sqrt^4 - rfYhat_sqrt^4)/y_test_sqrt^4<=0.2) & ((y_test_sqrt^4 - rfYhat_sqrt^4)/y_test_sqrt^4>=-0.05))
printf("We have the accuracy of the model approximately %.2f%%", rf_accuracy_sqrt*100)
```

### Variable Importance

Here we are going to show the top 10 most important variables in predicting sale price of a house.

```{r rfVarImportance1, fig.width=5,fig.height=2, fig.cap="Original Price Importance"}

# original importance plot
importance = importance(rfTrain_ori)
importancedf =  data.frame(Variables = row.names(importance), MSE = importance[,1])
importancedf <- importancedf[order(importancedf$MSE, decreasing = TRUE),]
ggplot(importancedf[1:10,], aes(x=reorder(Variables, MSE), y=MSE, fill=MSE)) + geom_bar(stat = 'identity') + labs(x = 'Variables', y= 'Importance', title="Importance of Each Predictor Predicting \n Original Price") + coord_flip() + theme(legend.position="none",plot.title = element_text(size = 8, face = "bold",hjust = 0.5),)+theme_minimal()
```
```{r rfVarImportance2, fig.width=5,fig.height=2, fig.cap="Log Transformed Price Importance"}
importance = importance(rfTrain_log)
importancedf =  data.frame(Variables = row.names(importance), MSE = importance[,1])
importancedf <- importancedf[order(importancedf$MSE, decreasing = TRUE),]
ggplot(importancedf[1:10,], aes(x=reorder(Variables, MSE), y=MSE, fill=MSE)) + geom_bar(stat = 'identity') + labs(x = 'Variables', y= 'Importance', title="Importance of Each Predictor Predicting \n Log Transformed Price") + coord_flip() + theme(legend.position="none",plot.title = element_text(size = 8, face = "bold",hjust = 0.5),)+theme_minimal()
```
```{r rfVarImportance3, fig.width=5,fig.height=2, fig.cap="Fourth Root Transformed Price Importance"}
importance = importance(rfTrain_sqrt)
importancedf =  data.frame(Variables = row.names(importance), MSE = importance[,1])
importancedf <- importancedf[order(importancedf$MSE, decreasing = TRUE),]
ggplot(importancedf[1:10,], aes(x=reorder(Variables, MSE), y=MSE, fill=MSE)) + geom_bar(stat = 'identity') + labs(x = 'Variables', y= 'Importance', title="Importance of Each Predictor Predicting \n Fourth Root Transformed Price") + coord_flip() + theme(legend.position="none",plot.title = element_text(size = 8, hjust = 0.5),)+theme_minimal()
```


From the above importance analysis, we could see the group of top ten most important predictors are the same for all three types of y-values. However, their importance varies a lot, but from the graph we could be assured that the top two most important predictors are the following:

\begin{enumerate}
\item TotalSqFeet (Total Area)
\item OverallQual (Overall Quality of the building)
\end{enumerate}


```{r RFCV}
set.seed(123) 
  
# computing model performance metrics 
# pander(data.frame( R2 = R2(rfYhat, y_test_ori), 
#             RMSE = RMSE(rfYhat, y_test_ori), 
#             MAE = MAE(rfYhat, y_test_ori)), title="Cross Validation for Random Forest")
r2rf = c(R2(rfYhat_ori, y_test_ori),R2(exp(rfYhat_log), exp(y_test_log)),R2(rfYhat_sqrt^4, y_test_sqrt^4))
rmserf = c(RMSE(rfYhat_ori, y_test_ori),RMSE(exp(rfYhat_log), exp(y_test_log)),RMSE(rfYhat_sqrt^4, y_test_sqrt^4))
accrf = c(rf_accuracy_ori,rf_accuracy_log,rf_accuracy_sqrt)
```

## 3. Principle Components Analysis (PCA) and Principle Components Regression (PCR)


### i. PCA

So far, our data totally has 216 columns of features (29 dense columns of numeric values and 187 sparse columns of one hot encoding values). In order to reduce the dimension of a mostly sparse feature matrix effectively, we applied the PCA method. Fortunately, we successfully reduced the dimension from 216 to no more than 32. 32 PCs have totally 99.997% of variance proportion. 17 PCs are enough for totally getting 85.068% of variance proportion. It is interesting that the number of PCs, 32, which is more than the number of dense columns, 29, shows that PCA has indeed extracted meaningful information from 187 sparse columns of one hot encoding and has successfully cut down the number of dimensions. 

```{r PCA} 

x_train_ori.pr = prcomp(x_train_ori) 

``` 

According to figure 10, we have found that all variance proportions behind 32th PC are 0, which means 32 PCs are totally enough important to describe all features of the original data. In fact, we can take less than 32 PCs and find the best number of PCs with cross validation in training process.

### ii. PCR

```{r PCA_description}
set.seed(2)
# PCA portion
train = sample(dim(train_ori)[1],size = dim(train_ori)[1]*0.7)
train.subset = train_ori[train,]
test = train_ori[-train,]
# bootstrap again
train.bs = sample(dim(train.subset)[1],replace = T)
train.df = train.subset[train.bs,]


# define a function to generate scree plots
pcaCharts <- function(x) {
  x.var <- x$sdev ^ 2
  x.pvar <- x.var/sum(x.var)
  # print("proportions of variance:")
  # print(x.pvar)
  
  par(mfrow=c(2,2))
  plot(x.pvar,xlab="Principal component", ylab="Proportion of variance", ylim=c(0,1), type='b',cex.lab=1, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
  plot(cumsum(x.pvar),xlab="Principal component", ylab="Cumulative", ylim=c(0,1), type='b',cex.lab=0.9, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
  screeplot(x,cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.8)
  screeplot(x,type="l",cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.8)
  par(mfrow=c(1,1))
}

x = subset(train.df, select = -c(SalePrice) )
train.pca <- prcomp(x ,center = TRUE)
#pcaCharts(train.pca)

########################### insert an image  (pca_plot.png) #################################
pcr_fit = pcr(SalePrice~., data = train.df,validation = "CV")
# # summary(pcr_fit)
# validationplot(pcr_fit, val.type = "MSEP",cex.lab=1, cex.axis=0.8, cex.main=1.5, cex.sub=0.8)
# axis(side = 1, at = c(32), cex.axis=0.8)
# abline(v = 32, col = "blue", lty = 5) 



########################### insert another image  (pcr_mse.png) #################################
```



```{r graph1,echo=FALSE, fig.width=8, fig.height=7, fig.cap="Principle Components Analysis"}
pcaCharts(train.pca)
```

Since we wanted to obtain as much variance as we could, but also trying to limit the number of predictors, we calculated the cross validation MSE for each number components in a pcr model to get a relatively ideal number of components. As we can see from the graph below, the cross validation MSE is the lowest when there are 29 components in the PCR model. Therefore we applied 29 components to test the result of our testing data set. 

```{r pcr_original}
# start pcr

pcr_fit = pcr(SalePrice~., data = train.df,validation = "CV")
pcr_pred = predict(pcr_fit,test)

accuracy.ori = mean((test$SalePrice - pcr_pred[,,29])/test$SalePrice<=0.2 & (test$SalePrice - pcr_pred[,,29])/test$SalePrice>=-0.05)


rsq <- function(x, y) summary(lm(y~x))$r.squared
rsq.ori = rsq(test$SalePrice,pcr_pred[,,29])

rmse <-  function(m, o){sqrt(mean((m - o)^2))}
rmse.ori = rmse(test$SalePrice,pcr_pred[,,29])


```

``` {r pcr_log}
set.seed(667)
train = sample(dim(train_log)[1],size = dim(train_log)[1]*0.7)
train.subset = train_log[train,]
test = train_log[-train,]
# bootstrap again
train.bs = sample(dim(train.subset)[1],replace = T)
train.df = train.subset[train.bs,]
pcr_fit = pcr(SalePrice~., data = train.df,validation = "CV")
pcr_pred = predict(pcr_fit,test)
accuracy.log = mean((exp(test$SalePrice) - exp(pcr_pred[,,29]))/exp(test$SalePrice<=0.2) & (exp(test$SalePrice) - exp(pcr_pred[,,29]))/exp(test$SalePrice)>=-0.05)

rsq.log = rsq(test$SalePrice,pcr_pred[,,29])
rmse.log = rmse(exp(test$SalePrice),exp(pcr_pred[,,29]))

```

``` {r pcr_sqrt}
set.seed(233)
train = sample(dim(train_sqrt)[1],size = dim(train_sqrt)[1]*0.7)
train.subset = train_sqrt[train,]
test = train_sqrt[-train,]
# bootstrap again
train.bs = sample(dim(train.subset)[1],replace = T)
train.df = train.subset[train.bs,]
pcr_fit = pcr(SalePrice~., data = train.df,validation = "CV")
pcr_pred = predict(pcr_fit,test)
accuracy.sqrt = mean((test$SalePrice^4 - pcr_pred[,,29]^4)/test$SalePrice^4<=0.2 & (test$SalePrice^4 - pcr_pred[,,29]^4)/test$SalePrice^4>=-0.05)

rsq.sqrt = rsq(test$SalePrice,pcr_pred[,,29])
rmse.sqrt = rmse(test$SalePrice^4,pcr_pred[,,29]^4)
```

``` {r pcr_cv, include=FALSE}
x <- data.frame("y" = c("original","log","sqrt"), "Accuracy" = c(accuracy.ori,accuracy.log,accuracy.sqrt), "R2" = c(rsq.ori,rsq.log,rsq.sqrt),"RMSE" = c(rmse.ori,rmse.log,rmse.sqrt))
pander(x)

accpcr = c(accuracy.ori,accuracy.log,accuracy.sqrt)
r2pcr = c(rsq.ori,rsq.log,rsq.sqrt)
rmsepcr = c(rmse.ori,rmse.log,rmse.sqrt)

```

## 4. Ridge Regression

### Explanation

In our data, the number of the data is relatively small compared to the number of the predictors, and we think there are some Multicollinearites within our predictors. All of these would cause overfitting. Under this circumstance, we think maybe linear regression would not perform pretty well. To prevent the overfitting and increase the explanatory power of the model, we will try to use some Shrinkage methods. In this case, we would use Ridge regression and Lasso regression. 

### Prepare Model

First, we set initial alpha to 0 to fit the ridge regression,and set the values of initial lambda ranging from $10^{-2}$ to $10^{10}$, essentially covering the full range of scenarios from the null model containing only the intercept, to the least squares fit.

```{r ridge }
# original
# original
Ridge_ori_accuracy= rep(0,k)
Ridge_ori_lambda = rep(0,k)
Ridge_ori_R2 = rep(0,k)
Ridge_ori_MAE = rep(0,k)
Ridge_ori_RMSE = rep(0,k)
Ridge_ori_coef = 0
Ridge_ori_train = rep(0,k)

for ( i in 1:k){
  set.seed(130+i)
  sample = sample(nrow(train_ori),nrow(train_ori),replace = T)
  ori_train = train_ori[sample,]
  train = sample(nrow(ori_train),0.7*nrow(ori_train))
  training_dataset = ori_train[train,]
  validation_dataset = ori_train[-train,]
  X_train = model.matrix(SalePrice~.,data = training_dataset)[,-1]
  X_test = model.matrix(SalePrice~.,validation_dataset)[,-1]
  y_train = training_dataset$SalePrice
  y_test = validation_dataset$SalePrice
  set.seed(1300+i)
  grid=10^seq(10,-2, length =100)
  Ridge.ori.Alpha=0
  Ridge.ori.Fit = glmnet(X_train, y_train, alpha=Ridge.ori.Alpha, lambda=grid)
  Ridge.ori.Fitcv = cv.glmnet(X_train, y_train, alpha = Ridge.ori.Alpha,nfolds = 10,type.measure = 'deviance')
  #Ridge.ori.Fitcv = cv.glmnet(X_train, y_train, alpha = Ridge.ori.Alpha,lambda = grid )
  Ridge.ori.lambda = Ridge.ori.Fitcv$lambda.min
  Ridge_ori_lambda[i] = Ridge.ori.lambda
  Ridge.ori.Pred <- predict(Ridge.ori.Fit, s= Ridge.ori.lambda, newx = X_test)
  Ridge.ori.Pred1 = predict(Ridge.ori.Fit, s= Ridge.ori.lambda, newx = X_train)
  Ridge_ori_train[i] = mean(-0.05<=(((Ridge.ori.Pred1)-(y_train))/(y_train))&(((Ridge.ori.Pred1)-(y_train))/(y_train)) <=0.2)
  Ridge.ori.coef = predict(Ridge.ori.Fit, s = Ridge.ori.lambda, type="coefficients")
  Ridge_ori_accuracy[i] = mean(-0.05<=(((Ridge.ori.Pred)-(y_test))/(y_test))&(((Ridge.ori.Pred)-(y_test))/(y_test)) <=0.2)
  Ridge_ori_R2[i] = R2(Ridge.ori.Pred,(y_test))
  Ridge_ori_RMSE[i]= RMSE(Ridge.ori.Pred,(y_test))
  Ridge_ori_MAE[i] = MAE(Ridge.ori.Pred,(y_test))
}
Ridge_ori_aver_lambda = mean(Ridge_ori_lambda)
Ridge_ori_aver_accuracy = mean(Ridge_ori_accuracy)
Ridge_ori_aver_RMSE = mean(Ridge_ori_RMSE)
Ridge_ori_aver_R2 = mean(Ridge_ori_R2)
Ridge_ori_aver_MAE = mean(Ridge_ori_MAE)
Ridge_ori_aver_train = mean(Ridge_ori_train)

# log transformation
Ridge_log_accuracy= rep(0,k)
Ridge_log_lambda = rep(0,k)
Ridge_log_R2 = rep(0,k)
Ridge_log_MAE = rep(0,k)
Ridge_log_RMSE = rep(0,k)
Ridge_log_coef = 0
Ridge_log_train = rep(0,k)
for ( i in 1:k){
  set.seed(220+i)
  sample = sample(nrow(train_log),nrow(train_log),replace = T)
  log_train = train_log[sample,]
  train = sample(nrow(log_train),0.7*nrow(log_train))
  training_dataset = log_train[train,]
  validation_dataset = log_train[-train,]
  X_train = model.matrix(SalePrice~.,data = training_dataset)[,-1]
  X_test = model.matrix(SalePrice~.,validation_dataset)[,-1]
  y_train = training_dataset$SalePrice
  y_test = validation_dataset$SalePrice
  set.seed(1220+i)
  grid=10^seq(10,-2, length =100)
  Ridge.log.Alpha=0
  Ridge.log.Fit = glmnet(X_train, y_train, alpha=Ridge.log.Alpha, lambda=grid)
  Ridge.log.Fitcv = cv.glmnet(X_train, y_train, alpha = Ridge.log.Alpha,nfolds = 10,type.measure = 'deviance')
  #Ridge.log.Fitcv = cv.glmnet(X_train, y_train, alpha = Ridge.log.Alpha,lambda = grid )
  Ridge.log.lambda = Ridge.log.Fitcv$lambda.min
  Ridge_log_lambda[i] = Ridge.log.lambda
  Ridge.log.Pred1 = predict(Ridge.log.Fit, s= Ridge.log.lambda, newx = X_train)
  Ridge.log.Pred1 = exp(Ridge.log.Pred1)
  Ridge_log_train[i] = mean(-0.05<=(((Ridge.log.Pred1)-exp(y_train))/exp(y_train))&(((Ridge.log.Pred1)-exp(y_train))/exp(y_train)) <=0.2)
  Ridge.log.Pred = predict(Ridge.log.Fit, s= Ridge.log.lambda, newx = X_test)
  Ridge.log.Pred = exp(Ridge.log.Pred)
  Ridge.log.coef = predict(Ridge.log.Fit, s = Ridge.log.lambda, type="coefficients")
  Ridge_log_accuracy[i] = mean(-0.05<=(((Ridge.log.Pred)-exp(y_test))/exp(y_test))&(((Ridge.log.Pred)-exp(y_test))/exp(y_test)) <=0.2)
  Ridge_log_R2[i] = R2(Ridge.log.Pred,exp(y_test))
  Ridge_log_RMSE[i]= RMSE(Ridge.log.Pred,exp(y_test))
  Ridge_log_MAE[i] = MAE(Ridge.log.Pred,exp(y_test))
}
Ridge_log_aver_lambda = mean(Ridge_log_lambda)
Ridge_log_aver_accuracy = mean(Ridge_log_accuracy)
Ridge_log_aver_RMSE = mean(Ridge_log_RMSE)
Ridge_log_aver_R2 = mean(Ridge_log_R2)
Ridge_log_aver_MAE = mean(Ridge_log_MAE)
Ridge_log_aver_train = mean(Ridge_log_train)


# sqrt 
Ridge_sqrt_accuracy= rep(0,k)
Ridge_sqrt_lambda = rep(0,k)
Ridge_sqrt_R2 = rep(0,k)
Ridge_sqrt_MAE = rep(0,k)
Ridge_sqrt_RMSE = rep(0,k)
Ridge_sqrt_coef = 0
Ridge_sqrt_train = rep(0,k)


for ( i in 1:k){
  set.seed(240+i)
  sample = sample(nrow(train_sqrt),nrow(train_sqrt),replace = T)
  sqrt_train = train_sqrt[sample,]
  train = sample(nrow(sqrt_train),0.7*nrow(sqrt_train))
  training_dataset = sqrt_train[train,]
  validation_dataset = sqrt_train[-train,]
  X_train = model.matrix(SalePrice~.,data = training_dataset)[,-1]
  X_test = model.matrix(SalePrice~.,validation_dataset)[,-1]
  y_train = training_dataset$SalePrice
  y_test = validation_dataset$SalePrice
  set.seed(1240+i)
  grid=10^seq(10,-2, length =100)
  Ridge.sqrt.Alpha=0
  Ridge.sqrt.Fit = glmnet(X_train, y_train, alpha=Ridge.sqrt.Alpha, lambda=grid)
  Ridge.sqrt.Fitcv = cv.glmnet(X_train, y_train, alpha = Ridge.sqrt.Alpha,nfolds = 10,type.measure = 'deviance')
  Ridge.sqrt.lambda = Ridge.sqrt.Fitcv$lambda.min
  Ridge_sqrt_lambda[i] = Ridge.sqrt.lambda
  Ridge.sqrt.Pred1 = predict(Ridge.sqrt.Fit, s= Ridge.sqrt.lambda, newx = X_train)
  Ridge.sqrt.Pred1 = (Ridge.sqrt.Pred1)^4
  Ridge_sqrt_train[i] = mean(-0.05<=(((Ridge.sqrt.Pred1)-(y_train)^4)/(y_train)^4)&(((Ridge.sqrt.Pred1)-(y_train)^4)/(y_train)^4) <=0.2)
  Ridge.sqrt.Pred = predict(Ridge.sqrt.Fit, s= Ridge.sqrt.lambda, newx = X_test)
  Ridge.sqrt.Pred = (Ridge.sqrt.Pred)^4
  Ridge.sqrt.coef = predict(Ridge.sqrt.Fit, s = Ridge.sqrt.lambda, type="coefficients")
  Ridge_sqrt_accuracy[i] = mean(-0.05<=(((Ridge.sqrt.Pred)-(y_test)^4)/(y_test)^4)&(((Ridge.sqrt.Pred)-(y_test)^4)/(y_test)^4) <=0.2)
  Ridge_sqrt_R2[i] = R2(Ridge.sqrt.Pred,(y_test)^4)
  Ridge_sqrt_RMSE[i]= RMSE(Ridge.sqrt.Pred,(y_test)^4)
  Ridge_sqrt_MAE[i] = MAE(Ridge.sqrt.Pred,(y_test)^4)
}
Ridge_sqrt_aver_lambda = mean(Ridge_sqrt_lambda)
Ridge_sqrt_aver_accuracy = mean(Ridge_sqrt_accuracy)
Ridge_sqrt_aver_RMSE = mean(Ridge_sqrt_RMSE)
Ridge_sqrt_aver_R2 = mean(Ridge_sqrt_R2)
Ridge_sqrt_aver_MAE = mean(Ridge_sqrt_MAE)
Ridge_sqrt_aver_train = mean(Ridge_sqrt_train)

```
``` {r finaltest}
setwd("~/Documents/DS502/DS502FinalProject")
test = read.csv("./SourceData/test_sqrt.csv")
X_test = model.matrix(SalePrice~.,test)[,-1]
y_test = test["SalePrice"]
set.seed(1240+i)
grid=10^seq(10,-2, length =100)
Ridge.sqrt.Alpha=0
Ridge.sqrt.Fit = glmnet(X_train, y_train, alpha=Ridge.sqrt.Alpha, lambda=grid)
Ridge.sqrt.Fitcv = cv.glmnet(X_train, y_train, alpha = Ridge.sqrt.Alpha,nfolds = 10,type.measure = 'deviance')
Ridge.sqrt.lambda = Ridge.sqrt.Fitcv$lambda.min
Ridge_sqrt_lambda = Ridge.sqrt.lambda
Ridge.sqrt.Pred1 = predict(Ridge.sqrt.Fit, s= Ridge.sqrt.lambda, newx = X_train)
Ridge.sqrt.Pred1 = (Ridge.sqrt.Pred1)^4
Ridge_sqrt_train = mean(-0.05<=(((Ridge.sqrt.Pred1)-(y_train)^4)/(y_train)^4)&(((Ridge.sqrt.Pred1)-(y_train)^4)/(y_train)^4) <=0.2)
Ridge.sqrt.Pred = predict(Ridge.sqrt.Fit, s= Ridge.sqrt.lambda, newx = X_test)
Ridge.sqrt.Pred = (Ridge.sqrt.Pred)^4
Ridge.sqrt.coef = predict(Ridge.sqrt.Fit, s = Ridge.sqrt.lambda, type="coefficients")
Ridge_sqrt_accuracy = mean(-0.05<=(((Ridge.sqrt.Pred)-(y_test)^4)/(y_test)^4)&(((Ridge.sqrt.Pred)-(y_test)^4)/(y_test)^4) <=0.2)
Ridge_sqrt_R2 = R2(Ridge.sqrt.Pred,(y_test)^4)
Ridge_sqrt_RMSE= RMSE(Ridge.sqrt.Pred,(y_test)^4)
Ridge_sqrt_MAE = MAE(Ridge.sqrt.Pred,(y_test)^4)

```

This is the optimal lambda computed by cross validation during the model training for Ridge Regression. as the following: 

```{r ridgeOplam}
# lambda of original 

# lambda of log transformation 

# lambda of sqrt transformation

temp = data.frame("y"=c("Original","Log","Fourth Rooted"), "lambda"=c(Ridge_ori_aver_lambda,Ridge_log_aver_lambda,Ridge_sqrt_aver_lambda))
pander(temp, caption="Lambda for Each Prediction")
#par(mfrow=c(2,2))
# plot(Ridge_ori_Fitcv)
# plot(Ridge_log_Fitcv)
# plot(Ridge_sqrt_Fitcv)
#(mfrow = c(1,1))
```

```{r ridgeAcc, include=FALSE}
# original accuracy
printf("Accuracy of Ridge is approximately %.2f%%", Ridge_ori_aver_accuracy*100)

# log accuracy
printf("Accuracy of Ridge with Log Transformation is approximately %.2f%%", Ridge_log_aver_accuracy*100)

# sqrt accuracy
printf("Accuracy of Ridge with Sqrt Transformation is approximately %.2f%%", Ridge_sqrt_aver_accuracy*100)

# accuracy dataframe
Ridge_accuracy_df = data.frame(Ridge = c('training accuracy','testing accuracy'),
                               ori_accuracy =c(Ridge_ori_aver_train,Ridge_ori_aver_accuracy),
                               log_accuracy =c(Ridge_log_aver_train,Ridge_log_aver_accuracy),
                            sqrt_accuracy=c(Ridge_sqrt_aver_train,Ridge_sqrt_aver_accuracy))

```

```{r ridgeCV, include=FALSE}
# ori
Ridge_ori_RMSE
pander(data.frame(R2 = Ridge_ori_aver_R2,RMSE = Ridge_ori_aver_RMSE,MAE = Ridge_ori_aver_MAE),title="Cross Validation of Ridge Regression")
# log
Ridge_log_RMSE
pander(data.frame(R2 = Ridge_log_aver_R2, RMSE = Ridge_log_aver_RMSE, MAE = Ridge_log_aver_MAE ), title="Cross Validation of Ridge Regression After Log Transformation")
# sqrt
Ridge_sqrt_RMSE
pander(data.frame(R2 = Ridge_sqrt_aver_R2, RMSE = Ridge_sqrt_aver_RMSE, MAE = Ridge_sqrt_aver_MAE), title="Cross Validation of Ridge Regression After Sqrt Transformation")

accRidge = c(Ridge_ori_aver_accuracy, Ridge_log_aver_accuracy, Ridge_sqrt_aver_accuracy)
r2Ridge = c(Ridge_ori_aver_R2, Ridge_log_aver_R2, Ridge_sqrt_aver_R2)
rmseRidge =  c(Ridge_ori_aver_RMSE, Ridge_log_aver_RMSE, Ridge_sqrt_aver_RMSE)
```

## 5. Lasso Regression

### Explanation 

Lasso is very similar to Ridge regression in that a penalty term is added to the regression optimization function(OLS) to prevent overfitting and  reduce the effect of Multicollinearity. 

But compare to ridge, Lasso use the L1-regulartion, which will shrink some parameters to 0, this could use for parameter selection and make the result more interpretable, could help us find out which parameter is what Lasso thinks is important.  

### Prepare Model 

Set the initial alpha is equal to 1 (Ridge regression is 0), and also use the same initial lambda, then try to use cross validation to choose the optimal lambda for Lasso after using different type of SalePrice 

According to different type of SalePrice, we conducted the model training for five times to each, and see how the model performened on average and whether the transformation in SalePrice will make the prediction better. 

```{r lasso}
# ori
k=5
Lasso_ori_accuracy= rep(0,k)
Lasso_ori_lambda = rep(0,k)
Lasso_ori_R2 = rep(0,k)
Lasso_ori_MAE = rep(0,k)
Lasso_ori_RMSE = rep(0,k)
Lasso_ori_coef = 0
Lasso_ori_train = rep(0,k)
for ( i in 1:k){
  set.seed(330+i)
  sample = sample(nrow(train_ori),nrow(train_ori),replace = T)
  ori_train = train_ori[sample,]
  train = sample(nrow(ori_train),0.7*nrow(ori_train))
  training_dataset = ori_train[train,]
  validation_dataset = ori_train[-train,]
  X_train = model.matrix(SalePrice~.,data = training_dataset)[,-1]
  X_test = model.matrix(SalePrice~.,validation_dataset)[,-1]
  y_train = training_dataset$SalePrice
  y_test = validation_dataset$SalePrice
  set.seed(1330+i)
  grid=10^seq(10,-2, length =100)
  Lasso.ori.Alpha=1
  Lasso.ori.Fit = glmnet(X_train, y_train, alpha=Lasso.ori.Alpha, lambda=grid)
  Lasso.ori.Fitcv = cv.glmnet(X_train, y_train, alpha = Lasso.ori.Alpha,nfolds = 10,type.measure = 'deviance')
  Lasso.ori.lambda = Lasso.ori.Fitcv$lambda.min
  Lasso_ori_lambda[i] = Lasso.ori.lambda
  Lasso.ori.Pred <- predict(Lasso.ori.Fit, s= Lasso.ori.lambda, newx = X_test)
  Lasso.ori.Pred1 <- predict(Lasso.ori.Fit, s= Lasso.ori.lambda, newx = X_train)
  Lasso.ori.coef = predict(Lasso.ori.Fit, s = Lasso.ori.lambda, type="coefficients")
  Lasso_ori_coef = Lasso_ori_coef + Lasso.ori.coef 
  Lasso_ori_train[i] = mean(-0.05<=(((Lasso.ori.Pred1)-(y_train))/(y_train))&(((Lasso.ori.Pred1)-(y_train))/(y_train)) <=0.2)
  Lasso_ori_accuracy[i] = mean(-0.05<=(((Lasso.ori.Pred)-(y_test))/(y_test))&(((Lasso.ori.Pred)-(y_test))/(y_test)) <=0.2)
  Lasso_ori_R2[i] = R2(Lasso.ori.Pred,(y_test))
  Lasso_ori_RMSE[i]= RMSE(Lasso.ori.Pred,(y_test))
  Lasso_ori_MAE[i] = MAE(Lasso.ori.Pred,(y_test))
}  
Lasso_ori_aver_lambda = mean(Lasso_ori_lambda)
Lasso_ori_aver_accuracy = mean(Lasso_ori_accuracy)
Lasso_ori_aver_RMSE = mean(Lasso_ori_RMSE)
Lasso_ori_aver_R2 = mean(Lasso_ori_R2)
Lasso_ori_aver_MAE = mean(Lasso_ori_MAE)
Lasso_ori_aver_train = mean(Lasso_ori_train)
n = length(Lasso.ori.coef)
Lasso_ori_aver_coef = (Lasso_ori_coef/5)[1:n,]


k = 5
Lasso_log_accuracy= rep(0,k)
Lasso_log_lambda = rep(0,k)
Lasso_log_R2 = rep(0,k)
Lasso_log_MAE = rep(0,k)
Lasso_log_RMSE = rep(0,k)
Lasso_log_coef = 0
Lasso_log_train = rep(0,k)
for ( i in 1:k){
  set.seed(60+i)
  sample = sample(nrow(train_log),nrow(train_log),replace = T)
  log_train = train_log[sample,]
  train = sample(nrow(log_train),0.7*nrow(log_train))
  training_dataset = log_train[train,]
  validation_dataset = log_train[-train,]
  X_train = model.matrix(SalePrice~.,data = training_dataset)[,-1]
  X_test = model.matrix(SalePrice~.,validation_dataset)[,-1]
  y_train = training_dataset$SalePrice
  y_test = validation_dataset$SalePrice
  set.seed(150+i)
  grid=10^seq(10,-2, length =100)
  Lasso.log.Alpha=1
  Lasso.log.Fit = glmnet(X_train, y_train, alpha=Lasso.log.Alpha, lambda=grid)
  #Lasso.log.Fitcv = cv.glmnet(X_train, y_train, alpha = Lasso.log.Alpha,nfolds = 10,type.measure = 'deviance')
  Lasso.log.Fitcv = cv.glmnet(X_train, y_train, alpha = Lasso.log.Alpha,lambda = grid)
  Lasso.log.lambda = Lasso.log.Fitcv$lambda.min
  Lasso_log_lambda[i] = Lasso.log.lambda
  Lasso.log.Pred <- predict(Lasso.log.Fit, s= Lasso.log.lambda, newx = X_test)
  Lasso.log.Pred = exp(Lasso.log.Pred)
  Lasso.log.Pred1 <- predict(Lasso.log.Fit, s= Lasso.log.lambda, newx = X_train)
  Lasso.log.Pred1 = exp(Lasso.log.Pred1)
  Lasso.log.coef = predict(Lasso.log.Fit, s = Lasso.log.lambda, type="coefficients")
  Lasso_log_coef = Lasso_log_coef + Lasso.log.coef
  Lasso_log_train[i] = mean(-0.05<=(((Lasso.log.Pred1)-exp(y_train))/exp(y_train))&(((Lasso.log.Pred1)-exp(y_train))/exp(y_train)) <=0.2)
  Lasso_log_accuracy[i] = mean(-0.05<=(((Lasso.log.Pred)-exp(y_test))/exp(y_test))&(((Lasso.log.Pred)-exp(y_test))/exp(y_test)) <=0.2)
  Lasso_log_R2[i] = R2(Lasso.log.Pred,exp(y_test))
  Lasso_log_RMSE[i]= RMSE(Lasso.log.Pred,exp(y_test))
  Lasso_log_MAE[i] = MAE(Lasso.log.Pred,exp(y_test))
}  
n = length(Lasso_log_coef)
Lasso_log_aver_coef = (Lasso_log_coef/5)[1:n,]
Lasso_log_aver_lambda = mean(Lasso_log_lambda)
Lasso_log_aver_accuracy = mean(Lasso_log_accuracy)
Lasso_log_aver_RMSE = mean(Lasso_log_RMSE)
Lasso_log_aver_R2 = mean(Lasso_log_R2)
Lasso_log_aver_MAE = mean(Lasso_log_MAE)
Lasso_log_aver_train = mean(Lasso_log_train)



# sqrt transformation
#sqrt
Lasso_sqrt_accuracy= rep(0,k)
Lasso_sqrt_lambda = rep(0,k)
Lasso_sqrt_R2 = rep(0,k)
Lasso_sqrt_MAE = rep(0,k)
Lasso_sqrt_RMSE = rep(0,k)
Lasso_sqrt_coef = 0
Lasso_sqrt_train = rep(0,k)
for ( i in 1:k){
  set.seed(100+i)
  sample = sample(nrow(train_sqrt),nrow(train_sqrt),replace = T)
  sqrt_train = train_sqrt[sample,]
  train = sample(nrow(sqrt_train),0.7*nrow(sqrt_train))
  training_dataset = sqrt_train[train,]
  validation_dataset = sqrt_train[-train,]
  X_train = model.matrix(SalePrice~.,data = training_dataset)[,-1]
  X_test = model.matrix(SalePrice~.,validation_dataset)[,-1]
  y_train = training_dataset$SalePrice
  y_test = validation_dataset$SalePrice
  set.seed(1370+i)
  grid=10^seq(10,-2, length =100)
  Lasso.sqrt.Alpha=1
  Lasso.sqrt.Fit = glmnet(X_train, y_train, alpha=Lasso.sqrt.Alpha, lambda=grid)
  Lasso.sqrt.Fitcv = cv.glmnet(X_train, y_train, alpha = Lasso.sqrt.Alpha,nfolds = 10,type.measure = 'deviance')
  Lasso.sqrt.lambda = Lasso.sqrt.Fitcv$lambda.min
  Lasso_sqrt_lambda[i] = Lasso.sqrt.lambda
  Lasso.sqrt.Pred = predict(Lasso.sqrt.Fit, s= Lasso.sqrt.lambda, newx = X_test)
  Lasso.sqrt.Pred = Lasso.sqrt.Pred^4
  Lasso.sqrt.Pred1 = predict(Lasso.sqrt.Fit, s= Lasso.sqrt.lambda, newx = X_train)
  Lasso.sqrt.Pred1 = Lasso.sqrt.Pred1^4
  Lasso.sqrt.coef = predict(Lasso.sqrt.Fit, s = Lasso.sqrt.lambda, type="coefficients")
  Lasso_sqrt_coef = Lasso_sqrt_coef + Lasso.sqrt.coef 
  Lasso_sqrt_train[i] = mean(-0.05<=(((Lasso.sqrt.Pred1)-(y_train)^4)/(y_train)^4)&(((Lasso.sqrt.Pred1)-(y_train)^4)/(y_train)^4) <=0.2)
  Lasso_sqrt_accuracy[i] = mean(-0.05<=(((Lasso.sqrt.Pred)-(y_test)^4)/(y_test)^4)&(((Lasso.sqrt.Pred)-(y_test)^4)/(y_test)^4) <=0.2)
  Lasso_sqrt_R2[i] = R2(Lasso.sqrt.Pred,(y_test)^4)
  Lasso_sqrt_RMSE[i]= RMSE(Lasso.sqrt.Pred,(y_test)^4)
  Lasso_sqrt_MAE[i] = MAE(Lasso.sqrt.Pred,(y_test)^4)
}  
n = length(Lasso_sqrt_coef)
Lasso_sqrt_aver_coef = (Lasso_sqrt_coef/5)[1:n,]
Lasso_sqrt_aver_lambda = mean(Lasso_sqrt_lambda)
Lasso_sqrt_aver_accuracy = mean(Lasso_sqrt_accuracy)
Lasso_sqrt_aver_RMSE = mean(Lasso_sqrt_RMSE)
Lasso_sqrt_aver_R2 = mean(Lasso_sqrt_R2)
Lasso_sqrt_aver_MAE = mean(Lasso_sqrt_MAE)
Lasso_sqrt_aver_train = mean(Lasso_sqrt_train)

```

This is the optimal lambda computed by cross validation during the model training for Lasso Regression. as the following: 

```{r lassoOplam}
# # lambda of original 
# Lasso_ori_aver_lambda
# # lambda of log transformation 
# Lasso_log_aver_lambda
# # lambda of sqrt transformation
# Lasso_sqrt_aver_lambda

temp = data.frame("y"=c("Original","Log","Fourth Rooted"), "lambda"=c(Lasso_ori_aver_lambda,Lasso_log_aver_lambda,Lasso_sqrt_aver_lambda))
pander(temp, caption="Lambda for Each Prediction")
#par(mfrow=c(2,2))
# plot(Lasso.ori.Fitcv)
# plot(Lasso.log.Fitcv)
# plot(Lasso.sqrt.Fitcv)
#par(mfrow = c(1,1))
```

### Coefficient From Lasso Regression 

Here we are going to show the predictors lasso chose 

```{r lassoVarImportance1, fig.width=5,fig.height=2, fig.cap="Original Price Importance"}
imp_ori_La = head(sort(Lasso_ori_aver_coef[Lasso_ori_aver_coef!=0][-1],decreasing = TRUE),20)
imp_ori_La<-data.frame(imp_ori_La)
#imp_ori_La
imp_ori_df <- data.frame(Variables = row.names(imp_ori_La),coef = imp_ori_La[,1])
#imp_df <- imp_df[order(imp_df$imp_La, decreasing = TRUE),]
ggplot(imp_ori_df[1:10,], aes(x=reorder(Variables, coef), y=coef, fill=coef)) + geom_bar(stat = 'identity') + labs(x = 'Variables', y= 'Importance', title="Importance of Each Predictor Predicting \n Log Transformed Price") + coord_flip() + theme(legend.position="none",plot.title = element_text(size = 8, face = "bold",hjust = 0.5),)+theme_minimal()
```
```{r lassoVarImportance2, fig.width=5,fig.height=2, fig.cap="Log Transformed Price Importance"}
#
#head(sort(Lasso_log_aver_coef[Lasso_log_aver_coef!=0][-1],decreasing = TRUE),20)
imp_log_La = head(sort(Lasso_log_aver_coef[Lasso_log_aver_coef!=0][-1],decreasing = TRUE),20)
imp_log_La<-data.frame(imp_log_La)
imp_log_df <- data.frame(Variables = row.names(imp_log_La),coef = imp_log_La[,1])

ggplot(imp_log_df[1:10,], aes(x=reorder(Variables, coef), y=coef, fill=coef)) + geom_bar(stat = 'identity') + labs(x = 'Variables', y= 'Importance', title="Importance of Each Predictor Predicting \n Log Transformed Price") + coord_flip() + theme(legend.position="none",plot.title = element_text(size = 8, face = "bold",hjust = 0.5),)+theme_minimal()
```
```{r lassoVarImportance3, fig.width=5,fig.height=2, fig.cap="Fourth Root Transformed Price Importance"}
#
imp_sqrt_La = head(sort(Lasso_sqrt_aver_coef[Lasso_sqrt_aver_coef!=0][-1],decreasing = TRUE),20)
imp_sqrt_La<-data.frame(imp_sqrt_La)
imp_sqrt_df <- data.frame(Variables = row.names(imp_sqrt_La),coef = imp_sqrt_La[,1])

ggplot(imp_sqrt_df[1:10,], aes(x=reorder(Variables, coef), y=coef, fill=coef)) + geom_bar(stat = 'identity') + labs(x = 'Variables', y= 'Importance', title="Importance of Each Predictor Predicting \n Log Transformed Price") + coord_flip() + theme(legend.position="none",plot.title = element_text(size = 8, face = "bold",hjust = 0.5),)+theme_minimal()
```

```{r lassoAcc, include=FALSE}
# original accuracy
printf("Accuracy of Lasso is approximately %.2f%%", Lasso_ori_aver_accuracy*100)
# log accuracy
printf("Accuracy of Lasso with Log Transformation is approximately %.2f%%", Lasso_log_aver_accuracy*100)
# sqrt accuracy
printf("Accuracy of Lasso with Sqrt Transformation is approximately %.2f%%", Lasso_sqrt_aver_accuracy*100)

# accuracy dataframe
Lasso_accuracy_df = data.frame(Lasso = c('training accuracy','testing accuracy'),
                               ori_accuracy =c(Lasso_ori_aver_train,Lasso_ori_aver_accuracy),
                               log_accuracy =c(Lasso_log_aver_train,Lasso_log_aver_accuracy),
                            sqrt_accuracy=c(Lasso_sqrt_aver_train,Lasso_sqrt_aver_accuracy))
```

```{r lassoCV, include=FALSE}
# ori
Lasso_ori_RMSE
Lasso_ori_aver_RMSE = mean(Lasso_ori_RMSE)
Lasso_ori_aver_R2 = mean(Lasso_ori_R2)
Lasso_ori_aver_MAE = mean(Lasso_ori_MAE)
pander(data.frame(R2 = Lasso_ori_aver_R2,RMSE = Lasso_ori_aver_RMSE,MAE = Lasso_ori_aver_MAE),title="Cross Validation of Lasso Regression")
# log
Lasso_log_RMSE
Lasso_log_aver_RMSE = mean(Lasso_log_RMSE)
Lasso_log_aver_R2 = mean(Lasso_log_R2)
Lasso_log_aver_MAE = mean(Lasso_log_MAE)
pander(data.frame(R2 = Lasso_log_aver_R2, RMSE = Lasso_log_aver_RMSE, MAE = Lasso_log_aver_MAE ), title="Cross Validation of Lasso Regression After Log Transformation")
# sqrt
Lasso_sqrt_RMSE
Lasso_sqrt_aver_RMSE = mean(Lasso_sqrt_RMSE)
Lasso_sqrt_aver_R2 = mean(Lasso_sqrt_R2)
Lasso_sqrt_aver_MAE = mean(Lasso_sqrt_MAE)
pander(data.frame(R2 = Lasso_sqrt_aver_R2, RMSE = Lasso_sqrt_aver_RMSE, MAE = Lasso_sqrt_aver_MAE), title="Cross Validation of Lasso Regression After Sqrt Transformation")

accLasso = c(Lasso_ori_aver_accuracy, Lasso_log_aver_accuracy,Lasso_sqrt_aver_accuracy)
r2Lasso = c(Lasso_ori_aver_R2, Lasso_log_aver_R2, Lasso_sqrt_aver_R2)
rmseLasso = c(Lasso_ori_aver_RMSE, Lasso_log_aver_RMSE, Lasso_sqrt_aver_RMSE)

```

# Evaluation of different models

We then need to check accuracy, as assumed before, we would look at whether the difference between predicted SalePrice and true SalePrice is within the range we define as accurate prediction. And compare the three reuslts computed by different type of SalePrice. The following is the result. We will select the model with least $R^2$ as a version of best model. 

```{r r2}
r2result = data.frame("y"=c("Original","Log", "Fourth Root"),
                      "Linear Regression" = r2Lr,
                      "Random Forest"=r2rf,
                      "PCR" = r2pcr,
                      "Ridge"=r2Ridge,
                      "Lasso"=r2Lasso)
pander(r2result, caption="R squared Error Metric")
```

```{r rmse}
rmseResult = data.frame("y"=c("Original","Log", "Fourth Root"),
                      "Linear Regression" = rmseLr,
                      "Random Forest"=rmserf,
                      "PCR" = rmsepcr,
                      "Ridge"=rmseRidge,
                      "Lasso"=rmseLasso)
pander(rmseResult, caption="RMSE Error Metric")
```

```{r accuracy}
accresult = data.frame("y"=c("Original","Log", "Fourth Root"),
                      "Linear Regression" = accLr,
                      "Random Forest"=accrf,
                      "PCR" = accpcr,
                      "Ridge"=accRidge,
                      "Lasso"=accLasso)
pander(accresult, caption="Accuracy Error Metric")
```

# Conclusion
From our observation in the error metric tables, we realize that RMSE works best in describing which ones of our models works the best in predicting the y-values. It is because it helps to penalize larger errors, while $R^2$ is not very decisive, and it could imply overfitting. Accuracy is an indicator that we created just to have an additional insight of how well the models perform. Thus, we take a closer look at RMSE for each model:

\begin{enumerate}
\item Lasso works the best for Original y-value
\item Ridge works the best for both Log and Fourth Root transformed y-value
\end{enumerate}

We then, could say that Ridge is the one we would like to use for our final validation and testing of prediction of House Price at North Ames, Iowa. From the above three error metric table, we could see that accuracy for each model has actually improved a little for each converted y-value. However, it is worth notice that most of the models are having trouble improving their R-squared or RMSE with a processed y-value, therefore showing a risk of overfitting original data with a converted y-value. 

At the end, we pulled our test data out from the vault and performed Ridge Regression over fourth-root transformation, the final result is 0.93 of R-square, 20449.24 of RMSE and approximately 60% of accuracy.
``` {r finalResult}
temp = data.frame("Error Metrics"=c("R2","RMSE","Accuracy"), "Value"=c(Ridge_sqrt_aver_R2,Ridge_sqrt_aver_RMSE,Ridge_sqrt_accuracy))
pander(temp, caption="Final Result")

```



# Discussion & Future Development

The challenges we face in this data set are having too few rows of data (only 1468 rows) while having a lot of predictors (both numeric and categorical), with a simple regression model might not be helpful to have a very accurate prediction. We can consider using ensemble method and other dimension reduction methods to increase its accuracy. Also, we did not take months into account to build our model, however months might affect the price of houses simply because people tend to buy houses in some seasons. We would try to use new methods and create more features to try to build a more robust and accurate model in the future.

\newpage

# Reference
